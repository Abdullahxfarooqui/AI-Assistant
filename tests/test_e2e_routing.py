"""
End-to-end integration test for query routing.
Demonstrates that general queries skip RAG and document queries use it.
"""

import sys
from pathlib import Path

# Add parent directory to path
sys.path.insert(0, str(Path(__file__).parent.parent))

from core.query_router import classify_query, should_use_rag, get_query_classification


def test_e2e_general_query():
    """End-to-end test: General query should NOT go through RAG"""
    print("\n" + "="*80)
    print("TEST 1: General Query - 'how to eat ice cream'")
    print("="*80)
    
    query = "how to eat ice cream"
    print(f"\nüìù Query: {query}")
    
    # Step 1: Classify
    classification = get_query_classification(query)
    print(f"\nüîç Classification Result:")
    print(f"   Type: {classification['type']}")
    print(f"   Confidence: {classification['confidence']:.2%}")
    print(f"   Reason: {classification['reason']}")
    
    # Step 2: Routing decision
    use_rag = should_use_rag(query)
    print(f"\nüõ£Ô∏è  Routing Decision: {'RAG Pipeline' if use_rag else 'Pure LLM Chat'}")
    
    # Step 3: Expected behavior
    print(f"\n‚úÖ Expected Behavior:")
    print(f"   - Skip vector search: YES")
    print(f"   - Skip embeddings: YES")
    print(f"   - Load dataset: NO")
    print(f"   - Show 'Data loaded' message: NO")
    print(f"   - Call LLM directly: YES")
    print(f"   - Show visualizations: NO")
    
    # Verify
    assert classification['type'] == 'general', "Should be classified as general"
    assert use_rag == False, "Should NOT use RAG"
    print(f"\n‚úÖ PASS: General query correctly bypasses RAG pipeline\n")


def test_e2e_rag_metric_query():
    """End-to-end test: Metric query SHOULD go through RAG"""
    print("\n" + "="*80)
    print("TEST 2: DATA Query - 'show me gas production'")
    print("="*80)
    
    query = "show me gas production"
    print(f"\nüìù Query: {query}")
    
    # Step 1: Classify
    classification = get_query_classification(query)
    print(f"\nüîç Classification Result:")
    print(f"   Type: {classification['type']}")
    print(f"   Confidence: {classification['confidence']:.2%}")
    print(f"   Reason: {classification['reason']}")
    
    # Step 2: Routing decision
    use_rag = should_use_rag(query)
    print(f"\nüõ£Ô∏è  Routing Decision: {'RAG Pipeline' if use_rag else 'Pure LLM Chat'}")
    
    # Step 3: Expected behavior
    print(f"\n‚úÖ Expected Behavior:")
    print(f"   - Skip vector search: NO")
    print(f"   - Skip embeddings: NO")
    print(f"   - Load dataset: YES")
    print(f"   - Show 'Data loaded' message: YES")
    print(f"   - Call LLM directly: NO (use RAG)")
    print(f"   - Show visualizations: YES (gas charts only)")
    
    # Verify
    assert classification['type'] == 'data', "Should be classified as data"
    assert use_rag == True, "Should use RAG"
    print(f"\n‚úÖ PASS: Metric query correctly uses RAG pipeline\n")


def test_e2e_rag_document_query():
    """End-to-end test: Document overview query SHOULD go through RAG"""
    print("\n" + "="*80)
    print("TEST 3: DATA Query - 'what is in the document'")
    print("="*80)
    
    query = "what is in the document"
    print(f"\nüìù Query: {query}")
    
    # Step 1: Classify
    classification = get_query_classification(query)
    print(f"\nüîç Classification Result:")
    print(f"   Type: {classification['type']}")
    print(f"   Confidence: {classification['confidence']:.2%}")
    print(f"   Reason: {classification['reason']}")
    
    # Step 2: Routing decision
    use_rag = should_use_rag(query)
    print(f"\nüõ£Ô∏è  Routing Decision: {'RAG Pipeline' if use_rag else 'Pure LLM Chat'}")
    
    # Step 3: Expected behavior
    print(f"\n‚úÖ Expected Behavior:")
    print(f"   - Skip vector search: NO")
    print(f"   - Skip embeddings: NO")
    print(f"   - Load dataset: YES")
    print(f"   - Show 'Data loaded' message: YES")
    print(f"   - Call LLM directly: NO (use RAG)")
    print(f"   - Show visualizations: NO (overview only)")
    
    # Verify
    assert classification['type'] == 'data', "Should be classified as data"
    assert use_rag == True, "Should use RAG"
    print(f"\n‚úÖ PASS: Document query correctly uses RAG pipeline\n")


def test_e2e_mixed_keywords():
    """Test: Query with both data and general keywords (data wins)"""
    print("\n" + "="*80)
    print("TEST 4: Mixed Keywords - 'how to interpret oil production data'")
    print("="*80)
    
    query = "how to interpret oil production data"
    print(f"\nüìù Query: {query}")
    
    # Step 1: Classify
    classification = get_query_classification(query)
    print(f"\nüîç Classification Result:")
    print(f"   Type: {classification['type']}")
    print(f"   Confidence: {classification['confidence']:.2%}")
    print(f"   Reason: {classification['reason']}")
    
    # Step 2: Routing decision
    use_rag = should_use_rag(query)
    print(f"\nüõ£Ô∏è  Routing Decision: {'RAG Pipeline' if use_rag else 'Pure LLM Chat'}")
    
    # Explanation
    print(f"\nüìä Analysis:")
    print(f"   DATA keywords: 'oil', 'production', 'data'")
    print(f"   General keywords: 'how to', 'interpret'")
    print(f"   Winner: DATA (dataset keywords present ‚Üí use RAG)")
    
    # Verify
    assert classification['type'] == 'data', "Should favor data query when data keywords present"
    print(f"\n‚úÖ PASS: Mixed query correctly prioritizes data context\n")


if __name__ == "__main__":
    print("\n")
    print("‚ïî" + "="*78 + "‚ïó")
    print("‚ïë" + " "*78 + "‚ïë")
    print("‚ïë" + "  END-TO-END QUERY ROUTING INTEGRATION TESTS".center(78) + "‚ïë")
    print("‚ïë" + " "*78 + "‚ïë")
    print("‚ïö" + "="*78 + "‚ïù")
    
    test_e2e_general_query()
    test_e2e_rag_metric_query()
    test_e2e_rag_document_query()
    test_e2e_mixed_keywords()
    
    print("\n" + "="*80)
    print("‚úÖ ALL INTEGRATION TESTS PASSED!")
    print("="*80)
    print("\nüìä Query Routing is working correctly:")
    print("   ‚úì General queries skip RAG pipeline")
    print("   ‚úì Document queries use RAG pipeline")
    print("   ‚úì Metric queries trigger visualizations")
    print("   ‚úì Mixed queries prioritize document context")
    print("\n")
